{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"./images/btp-banner.gif\" alt=\"BTP A&C\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an Orchestration Workflow using Generative AI Hub SDK\n",
    "In this demo, we will explore how to build an orchestration workflow using Generative AI Hub SDK. You will learn to combine different modules from orchestration into a pipeline that can be executed with a single API call. Within the pipeline, the response from one module is used as the input for the next module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯Learning Objectives\n",
    "By the end of this demo, you will be able to:\n",
    "- Describe orchestration feature in **Generative AI Hub**\n",
    "- Using **Generative AI Hub SDK** to interact with Orchestration services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš¨Requirements\n",
    "\n",
    "Please review the following requirements before starting the demo: \n",
    "- You have a running **orchestration deployment** in Generative AI Hub. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¼Use Case: Supplier Risk Analysis\n",
    "**Business Problem**:\n",
    "The company, BestRun SE, has launched a new project requiring their supply chain planner to identify the best supplier from several candidates. To support this, the planner gathered supplier data from various sources into a single file. The core challenge lies in evaluating supplier risk using key performance indicators such as reliability, quality, and market trends. This assessment is critical for making a well-informed supplier selection aligned with business goals.\n",
    "\n",
    "**Proposed Solution**:\n",
    "The solution analyzes supplier performance by evaluating metrics like quality, pricing, and delivery times while incorporating contextual data such as industry trends and past evaluations. Sensitive information is protected using data masking to anonymize personal details. An orchestration service integrates data ingestion, vector-based grounding, and large language model execution to streamline analysis, helping organizations gain deeper insights into supplier risk and improve procurement strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install Python Packages  \n",
    "Run the following package installations. **pip** is the package installer for Python. You can use pip to install packages from the Python Package Index and other indexes. \n",
    "\n",
    "**Note:** Jupyter Notebook kernel restart required after package installation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install generative-ai-hub-sdk[all] --break-system-packages\n",
    "%pip install python-dotenv --break-system-packages\n",
    "\n",
    "# kernel restart required!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âš ï¸The Python kernel needs to be restarted before continuing. \n",
    "\n",
    "> ![](./images/config_001.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initializing the Orchestration Service\n",
    "After orchestration deployment, you'll receive a unique endpoint URL. You can use the URL to access orchestration service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative AI Config\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "# Get the AI Core client ID from environment variables\n",
    "RESOURCE_GROUP = os.getenv('AICORE_RESOURCE_GROUP')\n",
    "# Get the Supplier Sourcing API URL from environment variables\n",
    "YOUR_API_URL = os.getenv('ORCH_DEPLOYMENT_URL')\n",
    "if not YOUR_API_URL:\n",
    "    raise ValueError(\"ORCH_DEPLOYMENT_URL is not set in your .env file.\")\n",
    "print(f\"Your Resource Group is {RESOURCE_GROUP}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data Grounding\n",
    "For the purpose of this exercise, this step has been simplified. In a real-world scenario, data preparation can be significantly more complex and time-consuming. The focus here is to highlight the essential steps involved in designing and executing an orchestration flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- import json package to read input file ---\n",
    "import json\n",
    "\n",
    "# --- Read Supplier Data from File ---\n",
    "with open('data/supplier_data.json', 'r', encoding='utf-8') as f:\n",
    "    sample_supplier_data = f.read()\n",
    "    \n",
    "# --- Read Grounding Data from File ---\n",
    "with open('data/grounding_data.json', 'r', encoding='utf-8') as f:\n",
    "    sample_grounding_data = f.read()\n",
    "\n",
    "print(\"âœ…The data has been imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we simplified text embedding on purpose in this exercise. We will introduce how to properly setup and run embedding in module 2, using SAP HANA Cloud Vector Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(text):\n",
    "    \"\"\"\n",
    "    Simulate text embedding.\n",
    "    In a real system, this would output a vector representation.\n",
    "    Here we simply return the text prefixed to indicate it's 'embedded'.\n",
    "    \"\"\"\n",
    "    # The returned 'vector' is just a placeholder string.\n",
    "    return f\"[Embedded Vector Representation of]: {text}\"\n",
    "\n",
    "def retrieve_relevant_context(embedded_grounding, query, top_k=1):\n",
    "    \"\"\"\n",
    "    Simulate a similarity search that retrieves the most relevant grounding context.\n",
    "    In a real implementation, you would perform a vector similarity search.\n",
    "    Here we simply return the original embedded grounding data.\n",
    "    \"\"\"\n",
    "    # For simplicity, we assume the entire embedded grounding is relevant.\n",
    "    return embedded_grounding\n",
    "\n",
    "# Simulate embedding and retrieval of grounding context \n",
    "embedded_grounding = embed_text(sample_grounding_data)\n",
    "# Simulate a retrieval step based on a query (here we use a dummy query for demonstration)\n",
    "query = \"What are the industry trends and internal evaluations affecting supplier performance?\"\n",
    "relevant_grounding_context = retrieve_relevant_context(embedded_grounding, query)\n",
    "\n",
    "print(\"âœ…The data has been embedded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Template Configuration\n",
    "The code sets up a template for a supplier evaluation assistant. It defines system and user messages to guide the evaluation process. The system message establishes the assistantâ€™s role as an AI specialized in supplier analysis, noting that sensitive information has been masked. The user message includes placeholders for supplier data and contextual grounding, instructing the assistant to analyze and recommend the best supplier based on quality, price, and delivery performance. This structure makes the template ready for use in AI-driven supplier assessment tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.template import Template\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "# Define a prompt template that now includes grounding context.\n",
    "template = Template(\n",
    "    messages=[\n",
    "        SystemMessage(\"You are an AI procurement assistant specialized in supplier evaluation. Note: Sensitive supplier information has been masked.\"),\n",
    "        UserMessage(\n",
    "            \"Given the following supplier data and additional grounding context, analyze and recommend the best supplier based on quality, price, and delivery performance. \\n\\nSupplier Data: {{?supplier_data}}\\n\\nGrounding Context: {{?grounding_context}}\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"âœ…The template has been defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Data masking \n",
    "The code maintains data privacy by using Data Masking techniques.  \n",
    "**Note:**  This step is optional; evaluate whether it is necessary based on the requirements of your particular use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.data_masking import DataMasking\n",
    "from gen_ai_hub.orchestration.models.sap_data_privacy_integration import SAPDataPrivacyIntegration, MaskingMethod, ProfileEntity\n",
    "# Create a proper data masking configuration\n",
    "data_masking = DataMasking(\n",
    "    providers=[\n",
    "        SAPDataPrivacyIntegration(\n",
    "            method=MaskingMethod.ANONYMIZATION,  # or MaskingMethod.PSEUDONYMIZATION\n",
    "            entities=[\n",
    "                ProfileEntity.EMAIL,\n",
    "                ProfileEntity.PHONE,\n",
    "                ProfileEntity.PERSON\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"âœ…The data masking has been configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Model Configuration\n",
    "The code imports the LLM class from the gen_ai_hub module, then creates an instance of an advanced language model, specifically \"gpt-4o\". This instance is configured with the latest version and tailored parameters like maximum token limit and temperature setting to control response variability. It sets the stage for scalable AI-driven text generation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "# Configure the Language Model (LLM) for processing.\n",
    "llm = LLM(\n",
    "    name=\"gpt-4o\",  # Replace with your model name if needed\n",
    "    version=\"latest\",\n",
    "    parameters={\"max_tokens\": 350, \"temperature\": 0.3}\n",
    ")\n",
    "\n",
    "print(f\"âœ…The LLM {llm.name} has been configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Create the Orchestration Configuration\n",
    "The code here imports the OrchestrationConfig class from the gen_ai_hub.orchestration.models.config module. It then initializes an instance of OrchestrationConfig using the template and LLM variables. This setup is necessary to configure the orchestration process, ensuring the system uses the specified template and language model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "# Create the orchestration configuration with the data masking config.\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    "    data_masking=data_masking  # Use the configuration object instead of a boolean\n",
    ")\n",
    "\n",
    "print(\"âœ…The orchestration workflow has been constrcuted successfully!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Run the Orchestration Request\n",
    "This code leverages the OrchestrationService to run a predefined task using specific template values. It connects to the service through the provided API URL and configuration, executes the task by supplying a text value, and then prints the resulting content. The code ensures streamlined communication with the orchestration system and retrieval of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.template import TemplateValue\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "# Now use YOUR_API_URL to instantiate the orchestration service\n",
    "orchestration_service = OrchestrationService(api_url=YOUR_API_URL, config=config)\n",
    "\n",
    "# Run the orchestration workflow by providing both the supplier data and the retrieved grounding context.\n",
    "result = orchestration_service.run(template_values=[\n",
    "    TemplateValue(name=\"supplier_data\", value=sample_supplier_data),\n",
    "    TemplateValue(name=\"grounding_context\", value=relevant_grounding_context)\n",
    "])\n",
    "# Print the recommendation output.\n",
    "print(\"Supplier Sourcing Recommendation with Data Masking and Grounding (Embedded):\")\n",
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
